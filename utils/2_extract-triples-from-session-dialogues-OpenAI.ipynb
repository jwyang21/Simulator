{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get environmental variables\n",
    "import os, sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "root_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import API keys\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import load_pickle, save_pickle, save_jsonl, remove_brackets, remove_quotes\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from datetime import date\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define openai agent\n",
    "class openai_agent():\n",
    "    def __init__(self, model, system_prompt, temperature, top_p, num_max_tokens):\n",
    "        self.model = model\n",
    "        if self.model == 'gpt-4o-mini':\n",
    "            self.api_model = 'gpt-4o-mini-2024-07-18'\n",
    "        elif self.model == 'gpt-4o':\n",
    "            self.api_model = 'gpt-4o-2024-08-06'\n",
    "        else:\n",
    "            self.api_model = ''\n",
    "        self.temperature = temperature\n",
    "        self.top_p = top_p\n",
    "        self.system_prompt = system_prompt\n",
    "        self.num_max_tokens = num_max_tokens\n",
    "        self.client = OpenAI()\n",
    "\n",
    "    def create_message(self, custom_id: str, user_prompt:str):\n",
    "        \"\"\"Creates message (dictionary) to run OpenAI API\"\"\"\n",
    "        message = {}\n",
    "        message['custom_id'] = custom_id\n",
    "        message['method'] = 'POST'\n",
    "        message['url'] = \"/v1/chat/completions\"\n",
    "        message['body'] = {}\n",
    "        message['body']['model'] = self.api_model\n",
    "        message['body']['top_p'] = self.top_p\n",
    "        message['body']['messages'] = [{\"role\":\"system\", \"content\": self.system_prompt}, {\"role\": \"user\", \"content\": user_prompt}]\n",
    "        message['body']['max_tokens'] = self.num_max_tokens\n",
    "        message['body']['temperature'] = self.temperature\n",
    "        return message\n",
    "    \n",
    "    def create_batch(self, data, data_type, prompt):\n",
    "        batch = []\n",
    "        for i in tqdm(range(len(data['session_dialogue'])), desc = 'creating data to run batch API (OpenAI)'):\n",
    "            entire_dialogue, partial_dialogue = data['session_dialogue'][i], data['partial_session_dialogue'][i]\n",
    "            custom_id = f'session{i}'\n",
    "            entire_prompt = prompt.replace('{input_text}', entire_dialogue)\n",
    "            partial_prompt = prompt.replace('{input_text}', partial_dialogue)\n",
    "            entire_message = self.create_message(custom_id+'_entire', entire_prompt)\n",
    "            partial_message = self.create_message(custom_id+'_partial', partial_prompt)\n",
    "            batch.append(entire_message)\n",
    "            batch.append(partial_message)\n",
    "        \n",
    "        batch_save_fname = os.path.join(root_dir, 'data', 'batch_api_tmp.jsonl')\n",
    "        save_jsonl(batch, batch_save_fname)\n",
    "\n",
    "        batch_input_file = self.client.files.create(\n",
    "            file = open(batch_save_fname, 'rb'),\n",
    "            purpose = \"batch\"\n",
    "        )\n",
    "\n",
    "        cmd_ = f'rm {batch_save_fname}'\n",
    "        os.system(cmd_)\n",
    "\n",
    "        today = date.today().strftime(\"%Y%m%d\")\n",
    "        batch_input_file_id = batch_input_file.id\n",
    "\n",
    "        uploaded_batch = self.client.batches.create(\n",
    "            input_file_id=batch_input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\n",
    "            \"description\": f\"triple_extraction ({data_type}, {today}, {self.api_model})\"\n",
    "            }\n",
    "        )\n",
    "        return uploaded_batch\n",
    "\n",
    "    def retrieve_recent_batches(self, n = 5):\n",
    "        return self.client.batches.list(limit=n).data\n",
    "\n",
    "    def retrieve_batch(self, batch_id):\n",
    "        return self.client.batches.retrieve(batch_id)\n",
    "\n",
    "    def get_batch_response(self, output_file_id):\n",
    "        file_response = self.client.files.content(output_file_id)#batch.output_file_id)\n",
    "        return file_response\n",
    "    \n",
    "    def cancel_batch_api(self, batch_id):\n",
    "        import requests\n",
    "        url = f\"https://api.openai.com/v1/batches/{batch_id}/cancel\"\n",
    "\n",
    "        # Send a POST request to cancel the batch\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.client.api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, headers=headers)\n",
    "\n",
    "        # Print the API response\n",
    "        print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "SCRIPT = 'friends'\n",
    "DATA_TYPE = 'normal' # newname, shuffled\n",
    "SYSTEM_PROMPT = 'You are a helpful assistant.'\n",
    "\n",
    "TRIAL_IDX = 0\n",
    "TEMPERATURE = 0.7\n",
    "TOP_P = 0.95\n",
    "NUM_MAX_TOKENS = 1000\n",
    "\n",
    "MODEL = 'gpt-4o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local variable\n",
    "triple_save_dir = os.path.join(root_dir, 'data', 'triple', SCRIPT, DATA_TYPE)\n",
    "if not os.path.exists(triple_save_dir):\n",
    "    os.makedirs(triple_save_dir)\n",
    "\n",
    "data_fname = os.path.join(root_dir, 'data', 'simul-log', SCRIPT, 'processed', DATA_TYPE, f'trial{TRIAL_IDX}.pickle')\n",
    "prompt_fname = os.path.join(root_dir, 'prompt', 'triple-extraction.v9-2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = load_pickle(data_fname)\n",
    "prompt = open(prompt_fname, 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = openai_agent(MODEL, SYSTEM_PROMPT, TEMPERATURE, TOP_P, NUM_MAX_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = agent.create_batch(data, DATA_TYPE, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.retrieve_recent_batches(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_response = agent.get_batch_response('file-As84A4AnToHCojDg68y3dC').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text로 all_response 저장 후 열기\n",
    "\n",
    "raw_output_fname = os.path.join(root_dir, 'data', 'batch_response_tmp.txt')\n",
    "with open(raw_output_fname, 'w') as f:\n",
    "    f.write(all_response) \n",
    "print(f'[Saved] {raw_output_fname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(raw_output_fname, 'r') as f:\n",
    "    raw_output = f.readlines()\n",
    "f.close()\n",
    "\n",
    "raw_output = [x.strip() for x in raw_output]\n",
    "\n",
    "cmd_ = f'rm {raw_output_fname}'\n",
    "os.system(cmd_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to json\n",
    "data_json = []\n",
    "for line in raw_output:\n",
    "    data_json.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dct = dict()\n",
    "for i in tqdm(range(len(data_json))):\n",
    "#for i in range(787, 788):\n",
    "#for i in range(713*2+1, 713*2+2): # 713th data for partial triples\n",
    "    id_ = data_json[i]['custom_id']\n",
    "    output_dct[id_] = {}\n",
    "    #result_ = [x.split(', ') for x in data_json[i]['response']['body']['choices'][0]['message']['content'].strip('[]').replace(\"(\", '').split('), ')]\n",
    "    #result_[-1][-1] = result_[-1][-1].strip(')')\n",
    "    raw_result_ = data_json[i]['response']['body']['choices'][0]['message']['content']\n",
    "    output_dct[id_]['raw'] = raw_result_\n",
    "    result_ = re.sub(r'{|}', '', data_json[i]['response']['body']['choices'][0]['message']['content'].strip('[]').strip())\n",
    "    if '\\n' in result_:\n",
    "        result_ = result_.split('\\n')\n",
    "        #result_ = [x.strip().replace('\"', '').replace(\"'\", '') for x in result_]\n",
    "        result_ = [remove_quotes(remove_brackets(x.strip())) for x in result_]\n",
    "    else:\n",
    "        if len(result_) > 0:\n",
    "            new_result_ = []\n",
    "            tmp_result_ = result_.split(', ')\n",
    "            for j in range(len(tmp_result_)//3):\n",
    "                new_result_.append(', '.join(tmp_result_[j*3:(j+1)*3]))\n",
    "                result_ = new_result_    \n",
    "    output_dct[id_]['processed'] = result_\n",
    "#print(len(id_), len(result_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_session_triples_raw, entire_session_triples_processed, partial_session_triples_raw, partial_session_triples_processed = [], [], [], []\n",
    "for i in tqdm(range(len(output_dct)//2), desc = 'splitting whole result into triples extracted from entire/partial session dialogue'):\n",
    "    entire_key, partial_key = list(output_dct)[2*i], list(output_dct)[2*i+1]\n",
    "    assert 'entire' in entire_key and 'partial' in partial_key\n",
    "    entire_session_triples_raw.append(output_dct[entire_key]['raw'])\n",
    "    entire_session_triples_processed.append(output_dct[entire_key]['processed'])\n",
    "    partial_session_triples_raw.append(output_dct[partial_key]['raw'])\n",
    "    partial_session_triples_processed.append(output_dct[partial_key]['processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data manually\n",
    "assert len(entire_session_triples_processed) == len(partial_session_triples_processed)\n",
    "print(len(entire_session_triples_processed), len(partial_session_triples_processed))\n",
    "\n",
    "random_indices = random.sample(range(0, len(entire_session_triples_processed)), 5)\n",
    "for index in random_indices:\n",
    "    print('='*40)\n",
    "    print(f'\\n[Index: {index}]')\n",
    "    print('\\n- Entire:')\n",
    "    print(entire_session_triples_processed[index])\n",
    "    print('\\n- Partial:')\n",
    "    print(partial_session_triples_processed[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_result = {}\n",
    "entire_result['entire_session_triples_raw'] = entire_session_triples_raw\n",
    "entire_result['entire_session_triples_processed'] = entire_session_triples_processed\n",
    "\n",
    "partial_result = {}\n",
    "partial_result['partial_session_triples_raw'] = partial_session_triples_raw\n",
    "partial_result['partial_session_triples_processed'] = partial_session_triples_processed\n",
    "\n",
    "print(entire_result.keys())\n",
    "print(partial_result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#version=1\n",
    "#version=2 # 20250507\n",
    "#version = 3 # 20250529, temperature = 0\n",
    "#version = 4 # 20250529, temperature = 0.75\n",
    "version = 5 # 20250604, temp = 0.7, top_p = 0.95\n",
    "\n",
    "entire_save_fname = os.path.join(triple_save_dir, 'entire-session', f'trial{TRIAL_IDX}', f'{agent.api_model}', f'v{version}.pickle')\n",
    "if not os.path.exists(os.path.join(triple_save_dir, 'entire-session', f'trial{TRIAL_IDX}', f'{agent.api_model}')):\n",
    "    os.makedirs(os.path.join(triple_save_dir, 'entire-session', f'trial{TRIAL_IDX}', f'{agent.api_model}'))\n",
    "save_pickle(entire_result, entire_save_fname)\n",
    "\n",
    "partial_save_fname = os.path.join(triple_save_dir, 'partial-session', f'trial{TRIAL_IDX}', f'{agent.api_model}', f'v{version}.pickle')\n",
    "if not os.path.exists(os.path.join(triple_save_dir, 'partial-session', f'trial{TRIAL_IDX}', f'{agent.api_model}')):\n",
    "    os.makedirs(os.path.join(triple_save_dir, 'partial-session', f'trial{TRIAL_IDX}', f'{agent.api_model}'))\n",
    "save_pickle(partial_result, partial_save_fname)\n",
    "\n",
    "# [Saved] /home/edlab/jwyang/research/dialsim-agent/data/triple/normal/trial0.normal.gpt-4o-mini-2024-07-18.pickle\n",
    "# [Saved] /home/edlab/jwyang/research/dialsim-agent/data/triple/shuffled/trial0.shuffled.gpt-4o-mini-2024-07-18.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out a part of result randomly\n",
    "random.sample(entire_result['entire_session_triples_processed'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dialsim-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
